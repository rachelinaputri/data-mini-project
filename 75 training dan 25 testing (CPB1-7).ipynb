{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrDIUlxmu229bN+HMUSZ19",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachelinaputri/data-mini-project/blob/main/miniproject2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fF19r5t__XEj",
        "outputId": "76993c52-35ab-4c60-98d2-8e44ced0a782"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SVM:\n",
            "Accuracy: 0.61\n",
            "F1-Score: 0.50\n",
            "Sensitivity: 1.00\n",
            "Specificity: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.70      0.88      0.78       192\n",
            "           B       0.00      0.00      0.00        53\n",
            "           C       0.50      0.85      0.63       122\n",
            "           D       0.00      0.00      0.00        83\n",
            "\n",
            "    accuracy                           0.61       450\n",
            "   macro avg       0.30      0.43      0.35       450\n",
            "weighted avg       0.43      0.61      0.50       450\n",
            "\n",
            "Evaluating K-NN:\n",
            "Accuracy: 0.64\n",
            "F1-Score: 0.61\n",
            "Sensitivity: 0.88\n",
            "Specificity: 0.09\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.69      0.86      0.76       192\n",
            "           B       0.17      0.09      0.12        53\n",
            "           C       0.69      0.67      0.68       122\n",
            "           D       0.56      0.40      0.46        83\n",
            "\n",
            "    accuracy                           0.64       450\n",
            "   macro avg       0.53      0.51      0.51       450\n",
            "weighted avg       0.60      0.64      0.61       450\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
        "\n",
        "# Paths to the CSV files\n",
        "file1_path = 'CPB1.csv'\n",
        "file2_path = 'CPB2.csv'\n",
        "file3_path = 'CPB3.csv'\n",
        "file4_path = 'CPB4.csv'\n",
        "file5_path = 'CPB5.csv'\n",
        "file6_path = 'CPB6.csv'\n",
        "file7_path = 'CPB7.csv'\n",
        "\n",
        "# Load the data from CSV files\n",
        "data1 = pd.read_csv(file1_path, delimiter=';')\n",
        "data2 = pd.read_csv(file2_path, delimiter=';')\n",
        "data3 = pd.read_csv(file3_path, delimiter=';')\n",
        "data4 = pd.read_csv(file4_path, delimiter=';')\n",
        "data5 = pd.read_csv(file5_path, delimiter=';')\n",
        "data6 = pd.read_csv(file6_path, delimiter=';')\n",
        "data7 = pd.read_csv(file7_path, delimiter=';')\n",
        "\n",
        "# Rename the target column in each dataframe for consistency\n",
        "data1.rename(columns={'kelas1': 'target'}, inplace=True)\n",
        "data2.rename(columns={'kelas2': 'target'}, inplace=True)\n",
        "data3.rename(columns={'kelas3': 'target'}, inplace=True)\n",
        "data4.rename(columns={'kelas4': 'target'}, inplace=True)\n",
        "data5.rename(columns={'kelas5': 'target'}, inplace=True)\n",
        "data6.rename(columns={'kelas6': 'target'}, inplace=True)\n",
        "data7.rename(columns={'kelas7': 'target'}, inplace=True)\n",
        "\n",
        "# Combine the three datasets\n",
        "combined_data = pd.concat([data1, data2, data3, data4, data5, data6, data7], ignore_index=True)\n",
        "\n",
        "# Convert decimal commas to dots and convert to float\n",
        "for column in ['powLv1', 'powLv2', 'powLv3', 'powLv4', 'powLv5']:\n",
        "    combined_data[column] = combined_data[column].str.replace(',', '.').astype(float)\n",
        "\n",
        "# Extract features and target\n",
        "X = combined_data.drop('target', axis=1)\n",
        "y = combined_data['target']\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define the SVM and K-NN models\n",
        "svm_model = SVC(kernel='rbf')\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions, average='weighted')\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"F1-Score: {f1:.2f}\")\n",
        "    print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "    print(f\"Specificity: {specificity:.2f}\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "# Split the data for the scenarios\n",
        "# 75% training, 25% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Evaluate SVM\n",
        "print(\"Evaluating SVM:\")\n",
        "evaluate_model(svm_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Evaluate K-NN\n",
        "print(\"Evaluating K-NN:\")\n",
        "evaluate_model(knn_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# You can add the same evaluation for the 50% training, 25% validation, 25% testing scenario by following a similar procedure."
      ]
    }
  ]
}
