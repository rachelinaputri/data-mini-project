{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rachelinaputri/data-mini-project/blob/main/miniproject1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWoaESSx9eKB",
        "outputId": "06938760-f93a-4c88-e4a0-1c13ff9d9404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating SVM:\n",
            "Accuracy: 0.66\n",
            "F1-Score: 0.60\n",
            "Sensitivity: 1.00\n",
            "Specificity: 0.00\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.59      0.84      0.69        70\n",
            "           B       0.00      0.00      0.00        30\n",
            "           E       0.75      0.75      0.75        75\n",
            "\n",
            "    accuracy                           0.66       175\n",
            "   macro avg       0.45      0.53      0.48       175\n",
            "weighted avg       0.56      0.66      0.60       175\n",
            "\n",
            "Evaluating K-NN:\n",
            "Accuracy: 0.61\n",
            "F1-Score: 0.58\n",
            "Sensitivity: 0.85\n",
            "Specificity: 0.08\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           A       0.54      0.76      0.63        70\n",
            "           B       0.15      0.07      0.09        30\n",
            "           E       0.80      0.68      0.73        75\n",
            "\n",
            "    accuracy                           0.61       175\n",
            "   macro avg       0.50      0.50      0.49       175\n",
            "weighted avg       0.58      0.61      0.58       175\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, f1_score, classification_report\n",
        "\n",
        "# Paths to the CSV files\n",
        "file1_path = 'CPA1.csv'\n",
        "file2_path = 'CPA2.csv'\n",
        "file3_path = 'CPA3.csv'\n",
        "\n",
        "# Load the data from CSV files\n",
        "data1 = pd.read_csv(file1_path, delimiter=';')\n",
        "data2 = pd.read_csv(file2_path, delimiter=';')\n",
        "data3 = pd.read_csv(file3_path, delimiter=';')\n",
        "\n",
        "# Rename the target column in each dataframe for consistency\n",
        "data1.rename(columns={'kelas1': 'target'}, inplace=True)\n",
        "data2.rename(columns={'kelas2': 'target'}, inplace=True)\n",
        "data3.rename(columns={'kelas3': 'target'}, inplace=True)\n",
        "\n",
        "# Combine the three datasets\n",
        "combined_data = pd.concat([data1, data2, data3], ignore_index=True)\n",
        "\n",
        "# Convert decimal commas to dots and convert to float\n",
        "for column in ['powLv1', 'powLv2', 'powLv3', 'powLv4', 'powLv5']:\n",
        "    combined_data[column] = combined_data[column].str.replace(',', '.').astype(float)\n",
        "\n",
        "# Extract features and target\n",
        "X = combined_data.drop('target', axis=1)\n",
        "y = combined_data['target']\n",
        "\n",
        "# Scaling the features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Define the SVM and K-NN models\n",
        "svm_model = SVC(kernel='rbf')\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "\n",
        "# Function to evaluate model\n",
        "def evaluate_model(model, X_train, X_test, y_train, y_test):\n",
        "    model.fit(X_train, y_train)\n",
        "    predictions = model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, predictions)\n",
        "    f1 = f1_score(y_test, predictions, average='weighted')\n",
        "    cm = confusion_matrix(y_test, predictions)\n",
        "    sensitivity = cm[0, 0] / (cm[0, 0] + cm[0, 1])\n",
        "    specificity = cm[1, 1] / (cm[1, 0] + cm[1, 1])\n",
        "    print(f\"Accuracy: {accuracy:.2f}\")\n",
        "    print(f\"F1-Score: {f1:.2f}\")\n",
        "    print(f\"Sensitivity: {sensitivity:.2f}\")\n",
        "    print(f\"Specificity: {specificity:.2f}\")\n",
        "    print(classification_report(y_test, predictions))\n",
        "\n",
        "# Split the data for the scenarios\n",
        "# 75% training, 25% testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25, random_state=42)\n",
        "\n",
        "# Evaluate SVM\n",
        "print(\"Evaluating SVM:\")\n",
        "evaluate_model(svm_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# Evaluate K-NN\n",
        "print(\"Evaluating K-NN:\")\n",
        "evaluate_model(knn_model, X_train, X_test, y_train, y_test)\n",
        "\n",
        "# You can add the same evaluation for the 50% training, 25% validation, 25% testing scenario by following a similar procedure.\n"
      ]
    }
  ]
}
